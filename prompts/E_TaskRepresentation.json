{
  "block": "E_TaskRepresentation",
  "features": [
    {
      "name": "Type of task",
      "question": "How is NER formulated (sequence-label, QA, etc.)?",
      "guideline": "- **Illustrative, not limiting:** Examples (sequence labeling, span classification, QA/MRC, generative extraction) are **illustrative**. **Do not** default to examples if they don’t fit the paper.\n- **Primary formulation rule:** Report the **formulation used by the final/best CTI-NER model**. If multiple formulations are discussed, put the **primary** one in **Answer** and list others under **“Not selected formulations”** in the Long explanation (with evidence).\n- **Inference from components (when unnamed):** If the paper **does not explicitly name** the formulation, **infer it** from the architecture/decoder and **cite** the components that justify it. Append **`(inferred from components)`** to the **Answer**. If still ambiguous, return **`Not reported`** and explain why.\n- **Disambiguation cues:**  \n  - **Sequence labeling:** presence of BIO/BILOU tags; token classifier or **CRF** over tag sequence  \n  - **Span classification:** start/end heads; candidate spans classified by type  \n  - **QA/MRC:** question/template per entity type; extractive answers as spans  \n  - **Generative extraction:** seq2seq/pointer network that **generates** entity strings\n- **Answer format:** **Single phrase + short clause**, e.g.,  \n  - `Sequence labeling — BIO tags with linear-chain CRF`  \n  - `Span classification — start/end heads with span type classifier`  \n  - `QA/MRC — question templates per entity type (inferred from components)`  \n  - `Generative extraction — seq2seq emits entity strings`\n\n**Output alignment**  \nConform **exactly** to the global per-field format (**Answer; Explanation & key points; Long explanation / description; Evidence**).  \n- **Answer:** single phrase + short clause (append `inferred from components` when applicable).  \n- **Explanation & key points:** one sentence stating **why** (point to the component/decoder).  \n- **Long explanation / description:** brief rationale tying components to the chosen formulation and listing **Not selected formulations** (if any) with evidence.  \n- **Evidence:** quotes naming the decisive component(s) (e.g., “linear-chain CRF”, “start/end classifier”, “we prompt with templates …”).",
      "model": "gpt-5-nano",
      "reasoning_effort": "medium"
    },
    {
      "name": "Embeddings/Features  used",
      "question": "Which embeddings or handcrafted features feed the model?",
      "guideline": "List **distinct embeddings/features** that feed the NER model.  \n\n- **Answer priority:** List **embeddings/features used by the final/best CTI-NER model first**, then list **all other tested embeddings/features**.  \n- **Synonyms:** Treat *embeddings*, *features*, *handcrafted features*, *featurizers*, *lexicons/gazetteers* as **equivalent** for extraction.  \n- **Illustrative, not limiting:** GloVe, fastText, Word2Vec, ELMo, BERT/RoBERTa/DeBERTa, domain-adapted LMs, character CNN, subword BPE, TF-IDF, POS, orthographic, **gazetteers/lexicons**.  \n- **Canonicalization & dedup:** Use **canonical names** (e.g., “GloVe 6B”, “BERT-base-uncased”, “fastText”). **Deduplicate** aliases/synonyms.  \n- **Creation method (when special):** If authors use a **special creation/derivation** (e.g., domain-adapted LM, continued pretraining, retrofitting, in-house fastText), briefly state **how it was created** (corpus/procedure) **as part of the item**.  \n- **Fusion note:** If multiple embeddings feed the model, indicate **fusion** (e.g., `concat`, `sum`, `attention gating`) **when stated**.  \n- **Two-pass recall sweep:** Scan **Methods/Architecture/Implementation** and **Appendix tables**; perform a **second pass** to catch missed items.  \n- **Evidence per item or group:** Provide **≥1 verbatim quote** (≤120 chars) for each **distinct embedding/feature** (or one quote for a group).",
      "model": "gpt-5-nano",
      "reasoning_effort": "medium"
    },
    {
      "name": "Embedding-effect study",
      "question": "Did authors analyse embedding choice?",
      "guideline": "Yes/No; if Yes add a  rationale."
    },
    {
      "name": "Hyperparameters",
      "question": "List hyperparameters explicitly reported.",
      "guideline": "- **Scope:** Collect **all explicitly reported hyperparameters** for the **final/best CTI-NER model**. \n- **Per-component grouping:** Define short **component aliases** (e.g., `enc`, `tagger`, `crf`, `emb_word`, `emb_char`). **Do not mix** hyperparameters across components.\n- **Answer format (qualified pairs):** Return comma-separated pairs as **`component.param=value`**. If a parameter is unambiguous to a single component, the alias may be omitted.\n- **Embeddings included:** Include hyperparameters of **embedding components** when **explicitly reported** (e.g., dims, vocab/casing, BPE merges).\n- **Exhaustiveness check:** Sweep **Methods**, **Implementation/Training details**, and **Appendix tables**. Perform a **second pass** to catch missed items.\n- **Normalization:** Use author names where possible; keep **numbers as numbers**; include units in **values** if given (e.g., `dropout=0.1`, `max_seq_len=512 tokens`).\n- **Evidence per item:** Provide **one quote** (≤120 chars) for each unique `param=value` (or a single quote that lists multiple params together). Quote **only body text or Markdown tables**.\n- **Not reported handling:** If a component has **no hyperparameters stated**, mark it in the **Long explanation** as `component: None reported` (do not invent values).\n\n**Output alignment**  \nConform **exactly** to the global per-field format defined in the system prompt (**Answer; Explanation & key points; Long explanation / description; Evidence**).  \nInside the **Long explanation**, include a Markdown table summarizing by component:\n\n| Component (alias) | Param | Value | Evidence (≤120 chars) |\n|---|---|---|---|\n| enc | hidden_size | 768 | “...encoder hidden size 768...” (Methods) |\n| tagger | dropout | 0.1 | “...tagger dropout of 0.1...” (Training) |\n| emb_char | char_dim | 50 | “...character embeddings of size 50...” (Setup) |"
    }
  ]
}